# NeRF Deep Benchmarking & Rendering (NeRF-DBR)

A comprehensive Neural Radiance Fields (NeRF) implementation with unified benchmarking across multiple execution methods. Compare performance of different rendering approaches using the **same trained model**, optimized for Apple Silicon and modern hardware.

## ğŸ¯ Project Overview

Train a NeRF model once, then benchmark different execution methods to compare pure performance rather than algorithmic differences. This provides insights into hardware utilization, memory efficiency, and deployment optimization strategies.

## ğŸ’» Development Hardware

This project was developed and tested on:

- **MacBook Pro** 14-Inch, Nov 2023
- **Chip** Apple M3 Pro
- **Memory** 36 GB
- **macOS** 15.5 (24F74)

_Performance benchmarks and optimizations are specifically tuned for Apple Silicon, though the system works cross-platform._

## âœ¨ Key Features

- **ğŸ§  Multiple Execution Methods** - PyTorch (MPS/CPU/CUDA), NumPy+Numba, CPU Optimized, Compressed NeRF
- **ğŸš€ Apple Silicon Optimized** - Automatic MPS acceleration with significant speedups
- **ğŸ”„ Unified Benchmarking** - Same trained model across all methods for fair comparison
- **ğŸ“Š Comprehensive Analysis** - Performance metrics, visual renders, and memory profiling
- **ğŸ§¹ Clean Architecture** - DRY principles, modular design, complete test coverage

## ğŸ—ï¸ Architecture

```
nerf-dbr/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/          # NeRF network implementation
â”‚   â”œâ”€â”€ data/            # Dataset loading utilities
â”‚   â”œâ”€â”€ training/        # Training loop and optimization
â”‚   â”œâ”€â”€ utils/           # Volume rendering utilities
â”‚   â””â”€â”€ benchmark/       # Unified benchmark system
â”‚       â”œâ”€â”€ pytorch_renderers.py    # MPS/CPU/CUDA implementations
â”‚       â”œâ”€â”€ numpy_renderer.py       # NumPy + Numba implementation
â”‚       â”œâ”€â”€ cpu_optimized_renderer.py   # Pure CPU optimized renderer
â”‚       â””â”€â”€ compressed_renderer.py      # Memory-efficient compressed renderer
â”œâ”€â”€ data/                # Datasets (synthetic, LLFF, 360Â°)
â”œâ”€â”€ checkpoints/         # Saved model weights
â”œâ”€â”€ outputs/             # Benchmark results and sample renders
â””â”€â”€ main.py              # Main training and benchmark script
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+**
- **macOS** (for MPS acceleration) or **Linux/Windows** (CPU/CUDA)
- **8GB+ RAM** recommended
- **Apple Silicon** for optimal performance

### 1. Setup Environment

```bash
# Clone repository (if from git)
git clone <repository-url>
cd nerf-dbr

# Make setup script executable and run
chmod +x setup.sh
./setup.sh

# Activate environment
source activate_nerf.sh
```

### 2. Get Dataset (if not included)

```bash
# Download official NeRF synthetic dataset
# Place in data/nerf_synthetic/lego/
# Or use your own NeRF-format dataset
```

### 3. Train and Benchmark

```bash
# Full pipeline: train + benchmark (recommended)
python main.py --epochs 50

# Quick training for testing
python main.py --epochs 5

# Benchmark only (if you have a trained model)
python main.py --benchmark_only

# Help and options
python main.py --help
```

### 4. Run Tests

```bash
# Complete test suite
python run_tests.py

# Individual tests
python test_system.py        # Unit tests
python test_integration.py   # Integration test
python smoke_test.py         # Pre-setup verification
```

## ğŸ“Š Benchmark Methods

The system compares these execution approaches using identical trained models:

### Available Renderers

| Method              | Description                    | Best For                   |
| ------------------- | ------------------------------ | -------------------------- |
| **PyTorch MPS**     | Apple Silicon GPU acceleration | Apple hardware development |
| **PyTorch CPU**     | Multi-threaded CPU execution   | Cross-platform baseline    |
| **PyTorch CUDA**    | NVIDIA GPU acceleration        | CUDA-enabled systems       |
| **NumPy + Numba**   | JIT-compiled CPU execution     | Lightweight deployment     |
| **CPU Optimized**   | Pure NumPy ray marching        | Maximum CPU efficiency     |
| **Compressed NeRF** | Quantized/pruned networks      | Edge/mobile deployment     |

### Performance Metrics

- **Render Time** - Latency per image (lower = better)
- **Rays/Second** - Throughput (higher = better)
- **Memory Usage** - Peak memory consumption
- **Visual Quality** - Saved sample renders for comparison

### Test Configurations

- **Resolutions**: 200Ã—150, 400Ã—300, 800Ã—600
- **Samples per ray**: 32, 64, 128
- **Multiple camera views** for statistical accuracy

## ï¿½ Output Files

All benchmark results and renders are saved to the `outputs/` directory:

```
outputs/
â”œâ”€â”€ benchmark_results.csv           # Detailed performance metrics
â”œâ”€â”€ performance_comparison.png      # Performance charts
â””â”€â”€ sample_renders/                # Visual quality comparison
    â”œâ”€â”€ PyTorch_MPS/
    â”‚   â”œâ”€â”€ view_0_rgb.png         # Color renders
    â”‚   â””â”€â”€ view_0_depth.png       # Depth maps
    â”œâ”€â”€ CPU_Optimized/
    â”œâ”€â”€ Compressed_NeRF/
    â””â”€â”€ NumPy_Numba/
```

## ğŸ›ï¸ Configuration

### Quick Start Options

```bash
# Full pipeline (recommended first run)
python main.py --epochs 50

# Quick test (5 minutes)
python main.py --epochs 5

# Benchmark only (reuse trained model)
python main.py --benchmark_only
```

### Epoch Recommendations

| Epochs | Time (M3 Pro) | Quality   | Use Case       |
| ------ | ------------- | --------- | -------------- |
| 5      | ~10 min       | Fair      | Quick testing  |
| 50     | ~1.5 hours    | Good      | Development    |
| 200    | ~6 hours      | Very Good | Demonstrations |
| 500+   | 15+ hours     | Excellent | Production     |

## ï¿½ï¸ Troubleshooting

### Quick Fixes

**MPS not available**

```bash
# Check Apple Silicon support
python -c "import torch; print('MPS:', torch.backends.mps.is_available())"
```

**Memory issues**

```bash
# Reduce memory usage
python main.py --epochs 5  # Use fewer epochs for testing
```

**Import errors**

```bash
# Ensure environment is activated
source activate_nerf.sh
pip install -r requirements.txt
```

### Performance Tips

- **Close other applications** during benchmarking
- **Use adequate cooling** for sustained performance
- **Monitor Activity Monitor** for resource usage
- **Try different epoch counts** to balance quality vs time

## ğŸ“š Technical Details

### Network Architecture

- **Input**: Positional encoded (x,y,z) + viewing direction
- **Architecture**: 8-layer MLP with skip connection at layer 4
- **Output**: Volume density Ïƒ + RGB color

### Volume Rendering

```
C(r) = âˆ‘ Ti Â· (1 - exp(-ÏƒiÂ·Î´i)) Â· ci
Ti = exp(-âˆ‘[j=1 to i-1] ÏƒjÂ·Î´j)
```

### Compression Techniques (Compressed NeRF)

- **Quantization**: 8-bit/16-bit weight precision
- **Pruning**: Remove smallest magnitude weights
- **Mixed Precision**: Float16/32 computation balance

## ğŸ”¬ Research Applications

- **Performance Analysis**: Compare execution methods across hardware
- **Hardware Optimization**: Evaluate Apple Silicon vs traditional platforms
- **Memory Efficiency**: Test compression techniques for edge deployment
- **Algorithm Development**: Benchmark new rendering approaches

## ï¿½ Testing

```bash
# Complete test suite
python run_tests.py

# Individual tests
python test_system.py        # Unit tests
python test_integration.py   # Integration tests
python smoke_test.py         # Quick verification
```

## ğŸ“„ License & Contributing

**MIT License** - Free for research and educational use.

**Contributing Guidelines:**

1. Follow clean, documented coding style
2. Add tests for new functionality
3. Update README for new features
4. Run full test suite: `python run_tests.py`

---

**Built with â¤ï¸ for clean, maintainable NeRF research on modern hardware.**

_Updated: June 13, 2025 - Now with CPU Optimized and Compressed NeRF renderers_
